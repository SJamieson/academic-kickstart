
@inproceedings{Girdhar2019_ICRA,
  title = {Streaming {{Scene Maps}} for {{Co}}-{{Robotic Exploration}} in {{Bandwidth Limited Environments}}},
  booktitle = {2019 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Girdhar, Yogesh and Cai, Levi and Jamieson, Stewart and McGuire, Nathan and Flaspohler, Genevieve and Suman, Stefano and Claus, Brian},
  year = {2019},
  month = may,
  pages = {7940--7946},
  publisher = {{IEEE}},
  address = {{Montr\'eal, Canada}},
  doi = {10/ggb46q},
  url = {https://arxiv.org/abs/1903.03214},
  abstract = {This paper proposes a bandwidth tunable technique for real-time probabilistic scene modeling and mapping to enable co-robotic exploration in communication constrained environments such as the deep sea. The parameters of the system enable the user to characterize the scene complexity represented by the map, which in turn determines the bandwidth requirements. The approach is demonstrated using an underwater robot that learns an unsupervised scene model of the environment and then uses this scene model to communicate the spatial distribution of various high-level semantic scene constructs to a human operator. Preliminary experiments in an artificially constructed tank environment as well as simulated missions over a 10m{{\texttimes}}10m coral reef using real data show the tunability of the maps to different bandwidth constraints and science interests. To our knowledge this is the first paper to quantify how the free parameters of the unsupervised scene model impact both the scientific utility of and bandwidth required to communicate the resulting scene model.},
  copyright = {All rights reserved},
  file = {/home/stewart/sync/Literature/IEEE/Girdhar et al. - 2019 - Streaming Scene Maps for Co-Robotic Exploration in Bandwidth Limited Environments.pdf},
  isbn = {978-1-5386-6027-0}
}

@phdthesis{Jamieson2018,
  title = {Deep {{Learning}} for {{Robust Vision}} in {{Realtime Autonomous Driving}}},
  author = {Jamieson, Stewart},
  year = {2018},
  month = jun,
  address = {{Toronto, Canada}},
  abstract = {The concept of robust vision is explored as a means to improve autonomous vehicle performance and safety. This research is applicable to both the University of Toronto's self-driving car team, aUToronto, as well as to manufacturers of autonomous road vehicles, who have been criticized for the failures of their vehicles that resulted in injuries and fatalities. The requirements of a robust vision system are identified; chiefly, it must be capable of uncertainty quantification, so this field is introduced and explored with respect to its applications in vision. With this foundation, the most commonly used computer vision algorithms are evaluated for robustness. Some experiments are performed using one of the most robust algorithms identified (Bayesian Neural Networks), on autonomous driving applications to demonstrate the advantages of uncertainty quantification. Noting that a major factor in the lack of usage of robust vision systems in autonomous driving is the computational cost, a proposal is made to use FPGAs to eliminate this relative disadvantage of Bayesian Neural Networks over the current most popular models. If future tests to validate the proposal are successful, this may pave the way for more robust vision systems to be adopted by autonomous vehicle manufacturers.},
  copyright = {All rights reserved},
  school = {University of Toronto},
  type = {B.{{A}}.{{Sc}}. {{Thesis}}}
}

@inproceedings{Jamieson2019,
  title = {The {{Pervasiveness}} of {{Deep Learning}} in {{Robotics Research Does Not Impede Scientific Insights}} into {{Robotics Problems}}},
  booktitle = {Debates on the {{Future}} of {{Robotics Research Workshop}} at {{ICRA}} 2019},
  author = {Jamieson, Stewart},
  year = {2019},
  month = may,
  address = {{Montr\'eal, Canada}},
  copyright = {All rights reserved}
}

@inproceedings{Jamieson2020,
  title = {Active {{Reward Learning}} for {{Co}}-{{Robotic Vision Based Exploration}} in {{Bandwidth Limited Environments}}},
  booktitle = {2020 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Jamieson, Stewart and How, Jonathan P. and Girdhar, Yogesh},
  year = {2020},
  month = may,
  publisher = {{IEEE}},
  address = {{Paris, France}},
  url = {https://arxiv.org/abs/2003.05016},
  abstract = {We present a novel POMDP problem formulation for a robot that must autonomously decide where to go to collect new and scientifically relevant images, given a limited ability to communicate with its human operator. From this formulation we derive constraints and design principles for the observation model, reward model, and communication strategy of such a robot, exploring techniques to deal with the very high-dimensional observation space and scarcity of relevant training data. We introduce a novel active reward learning strategy based on making queries to help the robot minimize path ``regret'' online and evaluate it for suitability in autonomous visual exploration through simulations. We demonstrate that, in some bandwidth limited environments, this novel regret-based criterion enables the robotic explorer to collect up to 17\textbackslash\% more reward per mission than the next-best criterion.},
  copyright = {All rights reserved},
  keywords = {Award: Winner of Best Paper Award in Service Robotics,Video: https://www.youtube.com/watch?v=NH1G8u2hbEU}
}

@phdthesis{Jamieson2020a,
  title = {Enabling {{Human}}-{{Robot Cooperation}} in {{Scientific Exploration}} of {{Bandwidth}}-{{Limited Environments}}},
  author = {Jamieson, Stewart},
  year = {2020},
  month = may,
  address = {{Cambridge, MA, USA}},
  doi = {10.1575/1912/25831},
  url = {https://darchive.mblwhoilibrary.org/handle/1912/25831},
  abstract = {Contemporary scientific exploration most often takes place in highly remote and dangerous environments, such as in the deep sea and on other planets. These environments are very hostile to humans, which makes robotic exploration the first and often the only option. However, they also impose restrictive limits on how much communication is possible, creating challenges in implementing remote command and control.},
  copyright = {All rights reserved},
  file = {/home/stewart/sync/Zotero/storage/Z5WLMLNK/Jamieson - Enabling Human-Robot Cooperation in Scientific Exp.pdf},
  school = {Massachusetts Institute of Technology},
  type = {Master's {{Thesis}}}
}


